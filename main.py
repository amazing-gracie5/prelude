# Main source code file for Prelude, this is where the app is built and run
# Author: Grace Simonson

from nicegui import ui, events
from abc import ABC, abstractmethod

# Code for the AudioRecorder class is from: https://github.com/zauberzeug/nicegui/tree/main/examples/audio_recorder/ (audio_recorder.py and audio_recorder.vue)
# Authors of AudioRecorder: Mansar Youness and Falko Schindler
from audio_recorder import AudioRecorder

from music21 import *

from pathlib import Path
import os
from datetime import datetime

# For handling MIDI files (a soundfont file and FluidSynth are also needed for handling MIDI files)
import subprocess

# For determining file type of uploaded files
import filetype
import re

# A dictionary for storing note values and their respective musical symbols (used in the Note Input Card)
NOTE_VAL_DICT = {0.25:'ùÖ°', 0.5:'ùÖ†', 1.0:'ùÖü', 2.0:'ùÖû', 4.0:'ùÖù', 0.75:'ùÖ†ùÖ≠', 1.5:'ùÖüùÖ≠', 3.0:'ùÖûùÖ≠', 6.0:'ùÖùùÖ≠'}

# Ensures current working directory is the same directory as main.py
current_path: Path = Path(__file__).parent.resolve()
os.chdir(current_path)

# Set path for soundfont file (AFTER the cwd is correctly set)
# The soundfont file used here was found at: https://member.keymusician.com/Member/FluidR3_GM/index.html, author: Frank Wen
SOUNDFONT_PATH = str(os.getcwd()) + '/FluidR3_GM.sf2'

# Create a directory to store files generated by Prelude
GEN_DIR = Path('generated_files')
GEN_DIR.mkdir(exist_ok=True)

# Create a directory to store files uploaded by the user
UPLOAD_DIR = Path('uploaded_files')
UPLOAD_DIR.mkdir(exist_ok=True)

# Main canvas class: this object provides the main workspace in the app and holds all draggable objects and their coordinate positions
class MainCanvas:
    def __init__(self):
        # Create the base NiceGUI interactive image that will contain all draggable objects within the MainCanvas
        # Note: col-span 11 only works within the grid I have set up in main code
        # Set cross=True to debug mouse events 
        self.canvasSpace = ui.interactive_image(size=(800, 600), cross=False).classes('col-span-11 bg-blue-50').style('position: relative')

    # Adds an object and its position to the object_positions dictionary (which keeps track of all objects within canvasSpace and their coordinate positions)
    # object: the object inside canvasSpace to be added to the dictionary
    # posX: the x coordinate of the object
    # posY: the y coordinate of the object
    # Note: this dictionary is not used elseware in the code, but could be helpful for better implementing the bring_to_front function
    def add_object(self, object, posX, posY):
        self.object_positions[object] = {'left': posX, 'top': posY}

    # To-do: implement bring to front function

# Draggable object class: the base abstract class for all objects that may be dragged and dropped in the Main Canvas
class DraggableObject(ABC):
    # Initializes the object's parent, x/y coordinates within the parent, isDragging boolean, and the highest z-index of parent (used in bring_to_front function)
    def __init__(self, input_parent, xPos=10, yPos=10):
        self.position = {'left': xPos, 'top': yPos} # Sets initial position of object, (10,10) by default
        self.isDragging = False # Initializes isDragging to False (used in functions related to drag and drop)
        self.parent = input_parent # Sets the parent to the given parent (usually a Main Canvas object)
        
        # Sets the current highest z-index (based on the number of children this object's parent has)
        # Note: the z-index is how far forward or back an object is, used in the bring_to_front function
        self.highest_z = len(self.parent.default_slot.children) + 1 # This object has yet to be initialized within the parent, so 1 is added

        # Common parent code for all DraggableObjects: sets mouse handlers for when the mouse is moved and released (see below for mouse handler code)
        with self.parent:
            self.parent.on('mousemove', self.on_mouse_move)
            self.parent.on('mouseup', self.on_mouse_up)
    
    # Abstract property ngui_element: concrete instances of DraggableObject must contain a ngui_element (an element from the NiceGUI library)
    @property
    @abstractmethod
    def ngui_element(self):
        pass

    # Mouse handler function for when the mouse goes down (clicked but not yet released)
    # event: the mousedown event object, which contains information about the specifics of the event
    def on_mouse_down(self, event):
        self.isDragging = True  # Object is now in the process of being dragged
       
       # Calculate the offset between the mouse coordinates and the coordinates of the object being dragged
        self.offset_x = event.args['x'] - self.position['left']
        self.offset_y = event.args['y'] - self.position['top']

    # Mouse handler function for when the mouse is moving (in other words, the 'drag' function)
    # event: the mousemove event object, which contains information about the specifics of the event
    def on_mouse_move(self, event):
        # isDragging is set to True when the mouse is clicked and not released, so this code should only run while the user attempts to drag the object across the screen
        if self.isDragging:
            # Update object position relative to the mouse coordinates
            new_left = event.args['x'] - self.offset_x
            new_top = event.args['y'] - self.offset_y
            self.ngui_element.style(f'position: absolute; left: {new_left}px; top: {new_top}px')
            self.position = {'left': new_left, 'top': new_top}
    
    # Mouse handler function for when mouse is released from a click (in other words, the 'drop' function)
    def on_mouse_up(self):
        self.isDragging = False # Object is no longer being dragged 
        # Object coordinates do not need to be updated, since they were properly set while the mouse was moving

    # Creates and returns the drag signifier on all idea cards, called during card creation
    def create_drag_icon(self):
        # Create a NiceGUI button with the drag_click icon in the upper left corner of its parent object (the Draggable Object calling this function)
        # Note: the drag_click icon does not appear on the button (bug)
        drag_icon = ui.button(on_click=lambda: 0, icon='drag_click').classes('size-10').style('position: absolute; left: -15px; top:-15px')
       
        # Set the mouse handler: when the drag_icon is clicked, the drag and drop process is started for the Draggable Object
        drag_icon.on('mousedown', self.on_mouse_down)
        return drag_icon
    
    # Brings the Draggle Object to the front of all objects (this is still in-progress and does not work correctly)
    def bring_to_front(self):
        # Sets the z-index to be the highest, bringing the object to the front
        # Note: storing the highest z-index individually within each Draggable Object is causing issues (this whole function should be moved to the parent Main Canvas object)
        self.ngui_element.style(f'z-index: {self.highest_z}; position: absolute; left: {self.position['left']}px; top: {self.position['top']}px')
        self.highest_z += 1

# Drawing Canvas class: a concrete implementation of DraggableObject. This class is used to implement any idea cards that have drawing functionality
#   All Drawing Canvases are comprised of a NiceGUI card containing a NiceGUI interactive image
class DrawingCanvas(DraggableObject):
    # Initializes the parent, background, content, and drawing settings for the Drawing Canvas
    # background: determines the type of Drawing Canvas and its background
    #   An empty string creates a sticky note, 'staff' creates a staff sticker, and anything else is assumed to be a filepath whose content will be the background
    def __init__(self, input_parent, background):
        # Initialize the Drawing Canvas as a Draggable Object with the specified parent
        super().__init__(input_parent) # Pass input parent to Draggable Object constructor

        # Initialize variables used in drawing functions
        self.starting_svg_content = ''
        self.added_svg_content = []
        self.drawing_path = ''
        self.is_drawing = False

        # 'with self.parent' ensures anything created inside the 'with' block will be the child of the specified parent (that is, contained within the parent)
        with self.parent:
            # Sets the abstract property ngui_element (from Draggable Object) to be a NiceGUI card
            # This is a bit clunky, but the width settings of the card matter depending on the type of drawing canvas
            if background == '':
                # Creates a NiceGUI card that will automatically size to the size of a sticky note (which will be contained in the card)
                self._ngui_element = ui.card().tight().style(f'position: absolute; left: {self.position['left']}px; top: {self.position['top']}px')
            else:
                # Creates a NiceGUI card that will be the width of half the screen (the height is automatically sized to fit the content of the card: either a staff sticker or image file)
                self._ngui_element = ui.card().tight().classes('w-1/2').style(f'position: absolute; left: {self.position['left']}px; top: {self.position['top']}px')
            
            # This 'with' block determines the content of the card created above
            with self.ngui_element:
                if background == '': # Card content is a sticky note (small green interactive image)
                    self.ii = ui.interactive_image(size=(1600, 1200), on_mouse=lambda e: self.drawing_mouse_handler(e), events=['mousedown', 'mousemove', 'mouseup'], cross=False).classes('w-64 bg-emerald-600')
                elif background == "staff": # Card content is a blank staff (interactive image with staff drawn onto it)
                    # The staff is drawn using SVG
                    self.starting_svg_content = '''
                        <line x1="10" y1="200" x2="990" y2="200" style="stroke:black;stroke-width:2" />
                        <line x1="10" y1="180" x2="990" y2="180" style="stroke:black;stroke-width:2" />
                        <line x1="10" y1="160" x2="990" y2="160" style="stroke:black;stroke-width:2" />
                        <line x1="10" y1="220" x2="990" y2="220" style="stroke:black;stroke-width:2" />
                        <line x1="10" y1="240" x2="990" y2="240" style="stroke:black;stroke-width:2" />
                        '''
                    # For some reason, setting width to w-1/2 doesn't work with a card as parent element for ii. Must use something else (size here is set manually)
                    self.ii = ui.interactive_image(size=(1000, 400), on_mouse=lambda e: self.drawing_mouse_handler(e), events=['mousedown', 'mousemove', 'mouseup'], cross=False, content=self.starting_svg_content).classes('w-full bg-white')
                else: # Any other background should be a file path to set the background to
                    # Card content is an interactive image with the file specified as the background
                    with ui.scroll_area().classes('w-full h-96'): # Adding a scroll area so generated cards aren't huge with paper-sized files (in the case of generated sheet music)
                        self.ii = ui.interactive_image(background, on_mouse=lambda e: self.drawing_mouse_handler(e), events=['mousedown', 'mousemove', 'mouseup'], cross=False).classes('w-full')
        
                # Give the card a drag icon
                canvas_drag_icon = self.create_drag_icon()
        
                # Context menu for all drawing canvases, contains 'clear drawings' and 'bring to front' options
                with ui.context_menu():
                    # For some reason, clearing drawings resets the scroll to the top of the page (why?)
                    ui.menu_item('Clear drawings', lambda: self.ii.set_content(self.starting_svg_content))
                    ui.menu_item('Bring to front', lambda: self.bring_to_front())

    # Mouse handling function for drawing. The path of the mouse (while clicked down) is added to the interactive image as SVG content
    def drawing_mouse_handler(self, e: events.MouseEventArguments):
        # Set the color and width of the drawing path
        color = 'Black'
        stroke_width = 2

        # When the mouse is clicked down (before being released), the drawing path begins
        if e.type == 'mousedown':
            self.is_drawing = True
            self.drawing_path = f'M {e.image_x} {e.image_y} '

        # When the mouse is moving while drawing is occuring (when the mouse is down), the path is recorded
        if self.is_drawing and e.type == 'mousemove':
            self.drawing_path += f'L {e.image_x} {e.image_y} '

        # When the mouse is released, drawing stops
        if e.type == 'mouseup':
            self.is_drawing = False

        # The recorded path is added to the interactive image as SVG content (on top of any existing content)
        self.ii.content += f'<path d="{self.drawing_path}" stroke="{color}" stroke-width="{stroke_width}" fill="none" />'
    
    # Returns the abstract property ngui_element
    @property
    def ngui_element(self):
        return self._ngui_element

# Audio Object class: a concrete implementation of Draggable Object. This class is used to implement idea cards that hold uploaded audio or audio generated from the Note Input Card
class AudioObject(DraggableObject):
    # Initializes the parent, audio source, and position of the Audio Object
    # audio_path: a file path to the source audio
    def __init__(self, input_parent, audio_path, xPos=10, yPos=10):
        # Initialize the Audio Object as a Draggable Object with the specified parent
        super().__init__(input_parent, xPos, yPos)

        with self.parent:
            # Sets the abstract property ngui_element to be a card (that automatically sizes to fit content placed inside it)
            self._ngui_element = ui.card().classes('bg-gray-100').style(f'position: absolute; left: {self.position['left']}px; top: {self.position['top']}px')
            with self.ngui_element:
                # Create a user-editable label for the card
                ui.input(label='Label', placeholder='Start typing').classes('w-full').props('dense="dense"')
                
                # Create a NiceGUI audio player using the specified audio source file path
                player = ui.audio(audio_path, autoplay=False)
                
                # Create a drag icon for the card
                audio_drag_icon = self.create_drag_icon()
    
    # Returns the abstract property ngui_element
    @property
    def ngui_element(self):
        return self._ngui_element

# Recorder Object class: implements Draggable Object. An idea card that allows the user to record live audio
class RecorderObject(DraggableObject):
    # Initializes style and controls of Recorder Object
    def __init__(self, input_parent):
        # Initializes the Recorder Object as a type of Draggable Object with the specified parent
        super().__init__(input_parent)

        with self.parent:
            # Sets the abstract property ngui_element as a NiceGUI card (that automatically sizes to fit its contents)
            self._ngui_element = ui.card().style(f'position: absolute; left: {self.position['left']}px; top: {self.position['top']}px')
            
            with self.ngui_element:
                # The code below is based on the example usage of the AudioRecorder class (written by Mansar Youness and Falko Schindler and found at https://github.com/zauberzeug/nicegui/tree/main/examples/audio_recorder/)
                audio_recorder = AudioRecorder(on_audio_ready=lambda data: ui.notify(f'Recorded {len(data)} bytes'))
                with ui.row().classes('w-full justify-center'):
                    ui.button('Play', on_click=audio_recorder.play_recorded_audio) \
                        .bind_enabled_from(audio_recorder, 'recording') # Button to play back recording
                    # Downloads as .ogx file
                    ui.button('Download', on_click=lambda: ui.download(audio_recorder.recording, 'audio.ogx')) \
                        .bind_enabled_from(audio_recorder, 'recording') # Button to download recording
                
                # Create a drag icon for the Recorder Object card
                audio_drag_icon = self.create_drag_icon()
    
    # Returns the abstract property ngui_element
    @property
    def ngui_element(self):
        return self._ngui_element

# Text Input class: a concrete impementation of Draggable Object, an idea card that stores text
class TextInput(DraggableObject):
    # Initializes style and controls of the Text Input object
    def __init__(self, input_parent):
        # Initializes the Text Input object as a type of Draggable Object with the specified parent
        super().__init__(input_parent) 
        
        with self.parent:
            # Sets the abstract property ngui_element as a NiceGUI card (that will automatically resize to fit its content)
            self._ngui_element = ui.card().style(f'position: absolute; left: {self.position['left']}px; top: {self.position['top']}px')
            
            with self.ngui_element:
                # Create drag icon for the Text Input object
                text_drag_icon = self.create_drag_icon()
                
                # NiceGUI's textarea element allows the user to input and edit persistent text
                ui.textarea(label='Text', placeholder='start typing')

    # Returns abstract property ngui_element
    @property
    def ngui_element(self):
        return self._ngui_element

# Draggable Icon class: a concrete implementation of Draggable Object. This class implements music symbol stickers
class DraggableIcon(DraggableObject):
    # Creates a note sticker with the specified symbol
    # icon_string: string of the music symbol used for the sticker
    def __init__(self, input_parent, icon_string):
        # Initializes the Draggable Icon as a Draggable Object with the specified parent
        super().__init__(input_parent)

        with self.parent:
            # Sets ngui_element as a NiceGUI button that displays the input icon_string
            self._ngui_element = ui.button(icon_string).props('flat fab color=black').style(f'font-size: 200%; font-weight: 300; position: absolute; left: {self.position['left']}px; top: {self.position['top']}px')
            
            # Sets the entire Draggable Icon as a draggable object (it does not have its own drag icon, instead, the user can directly click and drag the Draggable Icon)
            self.ngui_element.on('mousedown', self.on_mouse_down)
    
    # Returns the abstract property ngui_element
    @property
    def ngui_element(self):
        return self._ngui_element

# Stream Handler class. Directly handles a music21 stream by holding it, generating sheet music from it, and generating audio from it. Allows for easy interfacing of music21 streams with the rest of my code
class StreamHandler():
    # Initializes the Stream Handler to have either an empty stream or a stream generated from a MusicXML file
    # source: string filepath to musicXML file, if empty ('') will create an empty stream
    def __init__(self, source):
        if source == '': # No source means an empty stream is created
            self.mus_stream = stream.Stream()
        else: # If source is present, the MusicXML file is read in and copied to the stream
            self.mus_stream = converter.parse(source)
            # Debug message: prints the contents of the stream to the terminal
            self.mus_stream.show('text')
    
    # Generates an SVG file of the stream held by the Stream Handler, returns the file path to the generated SVG
    # Dependencies: needs LilyPond to be installed on the host computer
    # out_file: the base name of the file that will be generated (without file extention): a timestamp will be added to the file name
    def generate_SVG(self, out_file):
        # Generate a base file path to where the generated LilyPond and SVG files will be stored
        #   Adds timestamp to prevent identical file names
        file_path = f'{GEN_DIR}/{out_file}{datetime.now().strftime("%Y%m%d_%H%M%S_%f")}'

        # Generate an SVG file by creating a LilyPond text file (using music21 stream functions), editing the LilyPond file to have the formatting it needs, and generating the SVG from the edited LilyPond file
        
        # Create a LilyPond text file of the stream (at the specified file_path)
        lily_path = self.mus_stream.write('lily', file_path)
        # Debug message: prints file path of generated LilyPond file to the terminal
        print(f'Lily path created: {lily_path}')
        # A list of lines that need to be commented out of the LilyPond file (all cause issues in various ways)
        patterns_to_comment = [ 
            r"\\RemoveEmptyStaffContext", # This line causes bugs when left in
            r"\\override VerticalAxisGroup #'remove-first = ##t", # This line causes bugs when left in
            r'\\include "lilypond-book-preamble.ly"' # This line makes each line of music its own seperate file, when commented out the music will generate on a full page instead of line by line
        ]
        # Overwrites old LilyPond file with a new one that has the specified lines commented out
        comment_out_lines(lily_path, lily_path, patterns_to_comment)
        #set_to_landscape(lily_path, lily_path) # Puts generated music on a landscape page (instead of portrait, which is the default). Not currently in use
        # Uses LilyPond (on the host computer's command line) to generate an SVG file of the LilyPond file we generated and edited
        subprocess.run(['lilypond', '-fsvg', '-o', GEN_DIR, lily_path], check=False)
        # The final file path where the SVG file may be found
        generated_path = f'{lily_path}.svg'
        # Debug message: outputs the file path of the generated file to the terminal
        print(f'New file at: {generated_path}')
        
        # Return the file path to generated SVG file
        return generated_path
    
    # Generates a WAV file of the stream held by Stream Handler, returns the file path of the generated WAV file
    # Dependencies: needs FluidSynth to be installed on the host computer
    # out_file: the name of the WAV file that will be generated (without file extention): a timestamp will be added to the file name
    def generate_WAV(self, out_file):
        # Generate the file path to where the WAV file will be generated
        #   Timestamp is added to create a unique file name
        wav_path = f'{GEN_DIR}/{out_file}{datetime.now().strftime("%Y%m%d_%H%M%S_%f")}.wav'
        
        # Generate the file path for the temporary MIDI file
        temp_MIDI = f'{GEN_DIR}/generated_MIDI' # using the same file name for temp_MIDI means this will be overwritten every time (good, it's only needed while the function runs)
        
        # Generate a MIDI file of the stream at the temp_MIDI file path using music21 stream function
        self.mus_stream.write('midi', temp_MIDI)
        
        # Convert the MIDI file to a WAV file at the specified wav_path using FluidSynth (on the host computer's command line)
        subprocess.run(['fluidsynth', '-ni', SOUNDFONT_PATH, temp_MIDI, '-F', wav_path], check=True)
        
        # Return the file path to the generated WAV file
        return wav_path

# Note Input Card class: a concrete implementation of Draggable Object. Any GUI input of notated music is handled with this object
class NoteInputCard(DraggableObject):
    # Initialize controls and style of the Note Input Card
    def __init__(self, input_parent):
        # Initialize the Note Input Card as a Draggable Object with the specified parent
        super().__init__(input_parent)

        with self.parent:
            # Set the abstract property ngui_element as a NiceGUI card (that will automatically resize to fit its content)
            self._ngui_element = ui.card().style(f'position: absolute; left: {self.position['left']}px; top: {self.position['top']}px')
            
            with self.ngui_element:
                # Create a drag icon for the Note Input Card
                text_drag_icon = self.create_drag_icon()
                
                # Shows current notes in music21 stream
                self.container = ui.row()

                # Initialize empty music21 stream
                self.input_stream = StreamHandler('')
                self.input_note_duration = 1.0 # Default note value is set to quarter note
                self.input_note_octave = '4' # Default octave is set to 4
                
                self.input_time_signature = meter.TimeSignature() # Default is 4/4 (no need to specify here)
                self.input_stream.mus_stream.append(self.input_time_signature) # Add time signature to stream
                
                self.input_key = key.Key() # Default is C major (no need to specify here)
                self.input_stream.mus_stream.append(self.input_key) # Add key signature to stream

                self.input_clef = clef.clefFromString('treble') # Default clef is set to treble
                self.input_stream.mus_stream.append(self.input_clef) # Add clef to stream
                
                # Debug message: prints contents of stream to terminal
                self.input_stream.mus_stream.show('text')
            
                with ui.row().classes('w-full justify-between no-wrap'):
                    # Rhythm toggle input
                    rythmIn = ui.toggle(NOTE_VAL_DICT, value=1.0).on_value_change(lambda e: self.set_note_duration(e.value))

                    # Octave slider input (with label)
                    ui.label('Octave')
                    octave_input = ui.slider(min=1, max=7, value=4, on_change=lambda e: self.set_note_octave(e.value)).props(f'label-always snap')
            
                # Pitch input (row of buttons)
                with ui.row():
                    ui.button('C').on('click', lambda: self.add_note('C'))
                    ui.button('C#').on('click', lambda: self.add_note('C#'))
                    ui.button('D').on('click', lambda: self.add_note('D'))
                    ui.button('D#').on('click', lambda: self.add_note('D#'))
                    ui.button('E').on('click', lambda: self.add_note('E'))
                    ui.button('F').on('click', lambda: self.add_note('F'))
                    ui.button('F#').on('click', lambda: self.add_note('F#'))
                    ui.button('G').on('click', lambda: self.add_note('G'))
                    ui.button('G#').on('click', lambda: self.add_note('G#'))
                    ui.button('A').on('click', lambda: self.add_note('A'))
                    ui.button('A#').on('click', lambda: self.add_note('A#'))
                    ui.button('B').on('click', lambda: self.add_note('B'))
                
                # Clef, time signature, and key signature input
                with ui.grid(columns=3).classes('w-full justify-between'):
                    ui.label('Clef')
                    ui.label('Key signature')
                    ui.label('Time Signature')

                    # Clef radio button input (with tooltip to clarify how it works)
                    with ui.element():
                        ui.radio({'treble':'ùÑû', 'bass':'ùÑ¢'}, value='treble', on_change=lambda e: self.change_clef(e.value)).props('inline').style('font-size: 200%')
                        ui.tooltip('Set clef for entire fragment')
                    
                    # Key signature dropdown input (with tooltip to clarify how it works)
                    with ui.element():
                        ui.select({'C':'C (a)', 'G':'G (e)', 'D':'D (b)', 'A':'A (f‚ôØ)', 'E':'E (c‚ôØ)', 'B':'B (g‚ôØ)', 'F#':'F‚ôØ (d‚ôØ)', 'C#':'C‚ôØ (a‚ôØ)', 'F':'F (d)', 'B-':'B‚ô≠ (g)', 'E-':'E‚ô≠ (c)', 'A-':'A‚ô≠ (f)', 'D-':'D‚ô≠ (b‚ô≠)', 'G-':'G‚ô≠ (e‚ô≠)', 'C-':'C‚ô≠ (a‚ô≠)'}, label='Key signature', value='C', on_change=lambda e: self.change_key(e.value))
                        ui.tooltip('Set key for entire fragment')
                    
                    # Time signature dropdown input (with tooltip to clarify how it works)
                    with ui.element():
                        ui.select(['2/4', '3/4', '4/4', '5/4', '6/4', '3/8', '4/8', '5/8', '6/8', '7/8', '9/8', '12/8', '2/2', '3/2'], label='Time signature', value='4/4', on_change=lambda e: self.change_time_signature(e.value))
                        ui.tooltip('Set time signature for entire fragment')

                # Remove and clear buttons
                with ui.row():
                    ui.button('Remove', on_click=self.remove_note) # Pops last note of stream
                    ui.button('Clear', on_click=self.clear_notes) # Clears all notes from stream (does not reset clef, key, or time signature)
                
                # Export and generation buttons
                with ui.row():
                    # Creates a Note Edit Card (contains notated music and audio of the stream)
                    #   Note: self.parent (the parent of the Note Input Card) is assumed to be the workspace itself (a Main Canvas object)
                    ui.button('Generate music!', on_click=lambda: NoteEditCard(self.parent, self.input_stream.generate_SVG('new_svg'), self.input_stream))
                    # Creates a Drawing Canvas of the notated stream
                    ui.button('Generate sheet music (only)', on_click=lambda: DrawingCanvas(self.parent, self.input_stream.generate_SVG('new_svg')))
                    # Creates an Audio Object of the stream
                    ui.button('Generate audio (only)', on_click=lambda: AudioObject(self.parent, self.input_stream.generate_WAV('new_audio')))
                    # Export dropdown
                    with ui.dropdown_button('Export to', auto_close=True):
                        ui.item('MusicXML', on_click=lambda: ui.download(self.input_stream.mus_stream.write('musicxml', 'musicXMLDownload')))
                        ui.item('PDF', on_click=lambda: ui.download(self.input_stream.mus_stream.write('lily.pdf', 'musicPDFDownload')))
                        # Note: download file name will include the timestamp for WAV files
                        ui.item('WAV', on_click=lambda: ui.download(self.input_stream.generate_WAV('WAVDownload')))
                        ui.item('MIDI', on_click=lambda: ui.download(self.input_stream.mus_stream.write("midi", "MIDIdownload")))

    # Returns abstract property ngui_element
    @property
    def ngui_element(self):
        return self._ngui_element

    # Sets the current note duration (shown in the rhythm toggle)
    #   Note: the value in the toggle will change when the user adjusts it without this function. This function updates the internal value when this happens
    def set_note_duration(self, newDuration):
        self.input_note_duration = newDuration

    # Sets the current octave (shown in the octave slider)
    # Note: the value in the slider will change when the user adjusts it without this function. This function updates the internal value when this happens
    def set_note_octave(self, newOctave):
        self.input_note_octave = newOctave
    
    # Adds a note to the stream and updates the output
    # note_name: the pitch name of the note
    def add_note(self, note_name):
        with self.container:
            # Update note output
            ui.label(f'{note_name}{NOTE_VAL_DICT[self.input_note_duration]}')
            # Create a new music21 note with the specified note name and the currently set octave
            next_note = note.Note(f"{note_name}{self.input_note_octave}")
            # Set the new note's duration to the currently selected rhythm
            next_note.duration.quarterLength = self.input_note_duration
            # Add the new note to the stream
            self.input_stream.mus_stream.append(next_note)
            
            # Debug messages printed to the terminal
            print(f'Added {note_name}, length {next_note.duration}:')
            self.input_stream.mus_stream.show('text')

    # Removes the last note from the stream and updates the display
    def remove_note(self):
        if list(self.container): # Checks if there is anything in the display
            # Delete the last note from the display
            self.container.remove(-1)
            # Pop the last note from the stream
            self.input_stream.mus_stream.pop()
            
            # Debug messages printed to the terminal
            print('Popped last note:')
            self.input_stream.mus_stream.show('text')
        else: # Otherwise, the display and stream contain no notes and nothing happens
            None 
    
    # Deletes all notes from the stream and updates the display
    def clear_notes(self):
        # Clears the display
        self.container.clear()
        # Clears the stream
        self.input_stream.mus_stream.clear()
        
        # Reset key and time signature to their previously set values (which are cleared when stream is cleared)
        self.input_stream.mus_stream.keySignature = self.input_key
        self.input_stream.mus_stream.timeSignature = self.input_time_signature
        self.input_stream.mus_stream.clef = self.input_clef
        
        # Debug messages printed to the terminal
        print('Cleared stream:')
        self.input_stream.mus_stream.show('text')
    
    # Sets time signaature for entire stream
    # new_ratio_string: a string representing the time signature as a fraction (4/4 for example)
    def change_time_signature(self, new_ratio_string):
        # Update the time signature to be the one passed in
        self.input_time_signature.ratioString = new_ratio_string

        # Changes time signature of entire stream
        self.input_stream.mus_stream.timeSignature = self.input_time_signature
        
        # Messages to confirm the time signature was changed
        ui.notify(f'Time signature updated to {self.input_time_signature.ratioString}')
        print(f'Changed time signature to {self.input_time_signature.ratioString}')
        self.input_stream.mus_stream.show('text')

    # Sets key/key signature for entire stream
    # new_tonic: a string representing the pitch value of the new tonic for the new key
    def change_key(self, new_tonic):
        # Update the key signature to be the one passed in
        self.input_key = key.Key(new_tonic)

        # Change the key signature of the whole stream 
        self.input_stream.mus_stream.keySignature = self.input_key
        # Messages to confirm the key signature was changed
        ui.notify(f'Key changed to: {self.input_key}')
        print(f'Changed key to: {self.input_key}')
        self.input_stream.mus_stream.show('text')
    
    # Sets clef for entire stream
    # new_clef_string: string representing a clef ('treble' for example)
    def change_clef(self, new_clef_string):
        # Update the currently set clef
        self.input_clef = clef.clefFromString(new_clef_string)

        # Change the clef for the entire stream
        self.input_stream.mus_stream.clef = self.input_clef
        # Messages confirming the clef was changed
        ui.notify(f'Changed clef to: {self.input_clef}')
        print(f'Changed clef to {self.input_clef}:')
        self.input_stream.mus_stream.show('text')

# Note Edit Card class: extends the Drawing Canvas class, generates a Drawing Canvas of a stream and an accompanied Audio Object with the audio of the stream
class NoteEditCard(DrawingCanvas):
    # Initializes the controls and layout of the Note Input Card
    # background: file path to a generated SVG of the stream (note: could change this to be generated within this function for better abstraction)
    # in_stream_handler: a Stream Handler object containing the stream that will be displayed 
    def __init__(self, input_parent, background, in_stream_handler):
        # Initialize Note Edit Card as a Drawing Canvas with the notated stream as the background
        super().__init__(input_parent, background) # May change so in_stream_handler directly passes a generated SVG, which would remove the need to pass the background file to the constructor

        # Property to hold the Stream Handler of the stream we will be using
        self.stream_handler = in_stream_handler

        with self.ngui_element:
            # Place a new card inside the Drawing Canvas's card that will contain controls for the Note Edit Card (this basically adds space at the bottom of the Note Edit Card to add controls)
            with ui.card().classes('w-full'):
                # Export dropdown menu (the same as on the Note Input Card)
                with ui.dropdown_button('Export to', auto_close=True):
                    ui.item('MusicXML', on_click=lambda: ui.download(self.stream_handler.mus_stream.write('musicxml', 'musicXMLDownload')))
                    ui.item('PDF', on_click=lambda: ui.download(self.stream_handler.mus_stream.write('lily.pdf', 'musicPDFDownload')))
                    ui.item('WAV', on_click=lambda: ui.download(self.stream_handler.generate_WAV('WAVDownload')))
                    ui.item('MIDI', on_click=lambda: ui.download(self.stream_handler.mus_stream.write("midi", "MIDIdownload")))
        # Add an Audio Object with a generated WAV file of the stream
        # Note: since the Audio Object's parent is the Note Edit Card (specifially, the ngui_element card inherited from Drawing Canvas), all positioning and drag-and-drop functionality is in relation to the Note Edit Card.
        #   This means the Audio Object may be moved about freely in the space, but when the Note Edit Card is moved, the Audio Object moves with it
        linked_audio_player = AudioObject(self.ngui_element, self.stream_handler.generate_WAV('new_audio'), xPos=50, yPos=150)

# A function to handle uploaded files once they have been passed through the upload dialog
# e: the event passed from the upload dialog (contains information about the upload, such as the file itself)
# current_canvas: an object of type MainCanvas (where the idea from the file will be placed)
def handle_upload(e: events.UploadEventArguments, current_canvas):
    # Generate a file path based on the name of the uploaded file (it will be placed in the UPLOAD_DIR directory)
    file_path = os.path.join(UPLOAD_DIR, e.name)

    # Write the contents of the uploaded file to the location of the file path we just generated
    with open(file_path, 'wb') as f:
        f.write(e.content.read())
    
    # Guess the type of file using filetype (this library checks fancy stuff in the file to guess the type and can guess a certain range of file types)
    upload_type = filetype.guess(file_path)
    
    if upload_type == None: # Not one of filetype's possible types, must determine extension
        # Grab the extention of the file
        input_extension = Path(e.name).suffix # WILL NOT WORK if filename has a . in it
        # filetype library does not recognize musicXML files, so this manually checks if the file extention is a musicXML file
        #   Note: while the code below means this app affords processing uploaded musicXML file, this is not indicated to the user from within the app itself
        if input_extension == '.musicxml' or input_extension == '.mxl':
            # Load the musicXML contents into a Stream Handler
            uploadedStreamHandler = StreamHandler(file_path)
            # Generate a Note Edit Card based on the stream we just generated from the uploaded file
            #   Note: When uploading a music21-generated mxl, there are some artifacts (title, double bar line at end)
            NoteEditCard(current_canvas.canvasSpace, uploadedStreamHandler.generate_SVG('upload_svg'), uploadedStreamHandler.generate_WAV('upload_wav'))
        return
    
    # Confirms for the user that their file was uploaded
    ui.notify(f'Uploaded: {e.name} (a(n) {upload_type.mime} file)')
    
    # Add an audio player if file is an audio file
    if (re.findall(r"\Aaudio", upload_type.mime)):
        AudioObject(current_canvas.canvasSpace, file_path)
    # Add a drawing canvas with image as background if file is an image file
    elif (re.findall(r"\Aimage", upload_type.mime)):
        DrawingCanvas(current_canvas.canvasSpace, file_path)
    # Anything not caught by the filters before this is caught here (this usually only happens when the file has an incorrect file extention)
    else:
        ui.notify("Not an audio or image file!")

# Comments out lines in a LilyPond file
# in_file_path: File path to the file to be read in 
# out_file_path: File path to where the output file will be placed (the output file will be the same as the input file but with the specified lines commented out)
# patterns: a list of string patterns. Any line with the patterns will be commented out
# Note: this function is not currently used in the app, but shows how page settings may be adjusted in Python
def comment_out_lines(in_file_path, out_file_path, patterns):
    # Read in the starting file content
    with open(in_file_path, 'r') as file:
        lines = file.readlines()
    
    # Iterate through the input file and copy line-by-line to the output file, with the specified patterns commented out
    with open(out_file_path, 'w') as file:
        for line in lines:
            if any(re.search(pattern, line) for pattern in patterns):
                file.write(f"% {line}")  # Add LilyPond's comment character (%) at the start of the line
            else:
                file.write(line)

# Takes a LilyPond file and rewrites it to have landscape setting
# in_file_path: File path to the file that will be read in
# out_file_path: File path to where the output file will be placed (it will be the same as the input file but with added commands to adjust the page settings)
def set_to_landscape(in_file_path, out_file_path):
    landscape_command = '''#(set-default-paper-size "a4" 'landscape)''' # Command that changes page layout to landscape
    # Read in input file
    with open(in_file_path, 'r') as file:
        lines = file.readlines()
    
    # Copy material from input file to output file with the page layout command in the appropriate spot
    with open(out_file_path, 'w') as file:
        for line in lines:
            # Insert format command after version statement
            if re.findall(r'\\version', line): 
                print('Version statement found')
                file.write(line)
                file.write(f'{landscape_command}\n')
            else:
                file.write(line)

# BEGIN MAIN CODE (all classes and functions have been defined)

# Create the overall layout of Prelude
# Using a NiceGUI grid ensures everything in the top menu and sidebar aligns to the grid
with ui.grid(columns=12).classes('absolute top-0 left-0 m-0, w-screen, gap-0'):
    top_bar = ui.card().classes('col-span-full')
    side_bar = ui.expansion('Left expand menu!').classes('col-span-1')
    newMainCanvas = MainCanvas()

    # Create an upload dialog
    dialog = ui.dialog()
    with dialog:
        with ui.card():
            # Add a NiceGUI file upload chooser that only allows the upload of images, audio files, and MusicXML files
            ui.upload(on_upload=lambda event: handle_upload(event, newMainCanvas)).props('accept="audio/*, image/*, .musicxml, .mxl"')

    # Place idea creation buttons in the top bar
    with top_bar:
        with ui.row():
            ui.button('‚ô™', on_click=lambda: DraggableIcon(newMainCanvas.canvasSpace, '‚ô™')) # Symbol sticker
            ui.button('ùÑû', on_click=lambda: DraggableIcon(newMainCanvas.canvasSpace, 'ùÑû')) # Symbol sticker
            ui.button('Note input', on_click=lambda: NoteInputCard(newMainCanvas.canvasSpace)) # Note Input Card
            ui.button('staff sticker', on_click=lambda: DrawingCanvas(newMainCanvas.canvasSpace, 'staff')) # Staff sticker (based on Drawing Canvas)
            ui.button('sticky note', on_click=lambda: DrawingCanvas(newMainCanvas.canvasSpace, '')) # Sticky note (based on Drawing Canvas)
            ui.button('recorder', on_click=lambda: RecorderObject(newMainCanvas.canvasSpace)) # Recorder Object
            ui.button('text', on_click=lambda: TextInput(newMainCanvas.canvasSpace)) # Text Input
            ui.button('Upload audio/image', on_click=dialog.open) # Opens upload dialog
    # Place an expander in the left side bar (no controls have been put here yet)
    with side_bar:
        result = ui.label('inside left menu expansion')

# Start NiceGUI app :)
ui.run()